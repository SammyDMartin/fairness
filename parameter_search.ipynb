{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "demo_reject_option_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SammyDMartin/fairness/blob/main/parameter_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXgPpTHixLGo"
      },
      "source": [
        "# Contribution\n",
        "**Add the possibility to pass in arbitrary metric to the ROC or CPP fit function**\n",
        "\n",
        "**Perform (currently random) cross-validation search over weights in arbitarary fairness function and assess k-fold accuracy/fairness scores**\n",
        "\n",
        "*search over fairness weight hyperparameters*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDPhtiySyDZW"
      },
      "source": [
        "### **Step 1**\n",
        "Install aif360 and setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU-3Yn931e7G",
        "outputId": "df243e6e-3ba1-43b7-a524-cdbb280447a8"
      },
      "source": [
        "!git clone https://github.com/Trusted-AI/AIF360"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrLI8Amk1m5l",
        "outputId": "01beb758-ebdf-4a3d-a9b7-017019234c6f"
      },
      "source": [
        "%cd AIF360 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rRhJVUXMs6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19872378-d546-441f-fe25-a97ab9ee3473"
      },
      "source": [
        "%pip install '.[all]'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31V3grha3NNR"
      },
      "source": [
        "Download data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk-DyqaK3PxM",
        "outputId": "68f8de7a-54d5-4633-e1e9-dd035253cb91"
      },
      "source": [
        "import urllib.request \n",
        "\n",
        "urls = [\n",
        "  \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
        "\t\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
        "\t\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\",\n",
        "]\n",
        "\n",
        "filenames = [\n",
        "  \"/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.data\",\n",
        "  \"/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.test\",\n",
        "  \"/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.names\",\n",
        "]\n",
        "\n",
        "for i in range(len(urls)):\n",
        "  url = urls[i]\n",
        "  filename = filenames[i]\n",
        "  print(url)\n",
        "  print(filename)\n",
        "  urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaFfNOHqUfvA",
        "outputId": "8faa9cbc-9c7b-4230-b012-8ee1dc18466d"
      },
      "source": [
        "%cd examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0XaaJklFFTP"
      },
      "source": [
        "Define Modified CalibratedEqOddsPostprocessing and Reject Option Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVPYyLHAECFh"
      },
      "source": [
        "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
        "from aif360.metrics.binary_label_dataset_metric import BinaryLabelDatasetMetric\n",
        "from aif360.metrics.classification_metric import ClassificationMetric\n",
        "import numpy as np\n",
        "\n",
        "class VariableCEP(CalibratedEqOddsPostprocessing):\n",
        "    def set_NP(self, NP_rate):\n",
        "        self.fn_rate = NP_rate[0]\n",
        "        self.fp_rate = NP_rate[1]\n",
        "    \n",
        "\n",
        "def normed_rates(fp_rate, fn_rate):\n",
        "    norm_const = float(fp_rate + fn_rate) if\\\n",
        "                      (fp_rate != 0 and fn_rate != 0) else 1\n",
        "    return (fp_rate / norm_const), (fn_rate / norm_const)\n",
        "\n",
        "\n",
        "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
        "        import RejectOptionClassification\n",
        "\n",
        "class InquisitiveRejectOptionClassification(RejectOptionClassification):\n",
        "\n",
        "  def fit(self, dataset_true, dataset_pred, metric_fn=None):\n",
        "      \"\"\"Estimates the optimal classification threshold and margin for reject\n",
        "      option classification that optimizes the metric provided.\n",
        "      Note:\n",
        "          The `fit` function is a no-op for this algorithm.\n",
        "      Args:\n",
        "          dataset_true (BinaryLabelDataset): Dataset containing the true\n",
        "              `labels`.\n",
        "          dataset_pred (BinaryLabelDataset): Dataset containing the predicted\n",
        "              `scores`.\n",
        "      Returns:\n",
        "          RejectOptionClassification: Returns self.\n",
        "      \"\"\"\n",
        "      fair_metric_arr = np.zeros(self.num_class_thresh*self.num_ROC_margin)\n",
        "      balanced_acc_arr = np.zeros_like(fair_metric_arr)\n",
        "      ROC_margin_arr = np.zeros_like(fair_metric_arr)\n",
        "      class_thresh_arr = np.zeros_like(fair_metric_arr)\n",
        "\n",
        "      cnt = 0\n",
        "      # Iterate through class thresholds\n",
        "      for class_thresh in np.linspace(self.low_class_thresh,\n",
        "                                      self.high_class_thresh,\n",
        "                                      self.num_class_thresh):\n",
        "\n",
        "          self.classification_threshold = class_thresh\n",
        "          if class_thresh <= 0.5:\n",
        "              low_ROC_margin = 0.0\n",
        "              high_ROC_margin = class_thresh\n",
        "          else:\n",
        "              low_ROC_margin = 0.0\n",
        "              high_ROC_margin = (1.0-class_thresh)\n",
        "\n",
        "          # Iterate through ROC margins\n",
        "          for ROC_margin in np.linspace(\n",
        "                              low_ROC_margin,\n",
        "                              high_ROC_margin,\n",
        "                              self.num_ROC_margin):\n",
        "              self.ROC_margin = ROC_margin\n",
        "\n",
        "              # Predict using the current threshold and margin\n",
        "              dataset_transf_pred = self.predict(dataset_pred)\n",
        "\n",
        "              dataset_transf_metric_pred = BinaryLabelDatasetMetric(\n",
        "                                            dataset_transf_pred,\n",
        "                                            unprivileged_groups=self.unprivileged_groups,\n",
        "                                            privileged_groups=self.privileged_groups)\n",
        "              classified_transf_metric = ClassificationMetric(\n",
        "                                            dataset_true,\n",
        "                                            dataset_transf_pred,\n",
        "                                            unprivileged_groups=self.unprivileged_groups,\n",
        "                                            privileged_groups=self.privileged_groups)\n",
        "\n",
        "              ROC_margin_arr[cnt] = self.ROC_margin\n",
        "              class_thresh_arr[cnt] = self.classification_threshold\n",
        "\n",
        "              # Balanced accuracy and fairness metric computations\n",
        "              balanced_acc_arr[cnt] = 0.5*(classified_transf_metric.true_positive_rate()\\\n",
        "                                      +classified_transf_metric.true_negative_rate())\n",
        "              \n",
        "              ### THE ONLY CHANGE I MAKE TO THE FUNCTION IS HERE\n",
        "              if metric_fn:\n",
        "                  fair_metric_arr[cnt] = metric_fn(classified_transf_metric)\n",
        "              ###\n",
        "              \n",
        "              elif self.metric_name == \"Statistical parity difference\":\n",
        "                  fair_metric_arr[cnt] = dataset_transf_metric_pred.mean_difference()\n",
        "              elif self.metric_name == \"Average odds difference\":\n",
        "                  fair_metric_arr[cnt] = classified_transf_metric.average_odds_difference()\n",
        "              elif self.metric_name == \"Equal opportunity difference\":\n",
        "                  fair_metric_arr[cnt] = classified_transf_metric.equal_opportunity_difference()\n",
        "              \n",
        "              \n",
        "\n",
        "              cnt += 1\n",
        "\n",
        "      rel_inds = np.logical_and(fair_metric_arr >= self.metric_lb,\n",
        "                                fair_metric_arr <= self.metric_ub)\n",
        "      if any(rel_inds):\n",
        "          best_ind = np.where(balanced_acc_arr[rel_inds]\n",
        "                              == np.max(balanced_acc_arr[rel_inds]))[0][0]\n",
        "      else:\n",
        "          print(\"Unable to satisfy fairness constraints\")\n",
        "          rel_inds = np.ones(len(fair_metric_arr), dtype=bool)\n",
        "          best_ind = np.where(fair_metric_arr[rel_inds]\n",
        "                              == np.min(fair_metric_arr[rel_inds]))[0][0]\n",
        "\n",
        "      self.ROC_margin = ROC_margin_arr[rel_inds][best_ind]\n",
        "      self.classification_threshold = class_thresh_arr[rel_inds][best_ind]\n",
        "\n",
        "      return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W45OSKC6FMby"
      },
      "source": [
        "Import Everything needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4MRumjXE_Br"
      },
      "source": [
        "# Load all necessary packages\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
        "                import load_preproc_data_adult, load_preproc_data_compas\n",
        "\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "from sklearn.model_selection import KFold as cross_val_split\n",
        "from scipy import optimize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkS9_FuTEmV7"
      },
      "source": [
        "## import dataset - use compas\n",
        "dataset_used = \"adult\" # \"adult\", \"german\", \"compas\"\n",
        "protected_attribute_used = 1 # 1, 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhNVAv3fEq93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cf85682-2043-4019-b13a-6a01860e3280"
      },
      "source": [
        "# code to identify the protected attributes from all of the dataset features\n",
        "if dataset_used == \"adult\":\n",
        "    dataset_orig = AdultDataset()\n",
        "#     dataset_orig = load_preproc_data_adult()\n",
        "    if protected_attribute_used == 1:\n",
        "        privileged_groups = [{'sex': 1}]\n",
        "        unprivileged_groups = [{'sex': 0}]\n",
        "    else:\n",
        "        privileged_groups = [{'race': 1}]\n",
        "        unprivileged_groups = [{'race': 0}]\n",
        "    \n",
        "elif dataset_used == \"german\":\n",
        "    dataset_orig = GermanDataset()\n",
        "    if protected_attribute_used == 1:\n",
        "        privileged_groups = [{'sex': 1}]\n",
        "        unprivileged_groups = [{'sex': 0}]\n",
        "    else:\n",
        "        privileged_groups = [{'age': 1}]\n",
        "        unprivileged_groups = [{'age': 0}]\n",
        "    \n",
        "elif dataset_used == \"compas\":\n",
        "#     dataset_orig = CompasDataset()\n",
        "    dataset_orig = load_preproc_data_compas()\n",
        "    if protected_attribute_used == 1:\n",
        "        privileged_groups = [{'sex': 1}]\n",
        "        unprivileged_groups = [{'sex': 0}]\n",
        "    else:\n",
        "        privileged_groups = [{'race': 1}]\n",
        "        unprivileged_groups = [{'race': 0}]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKwIcBsRGPEQ"
      },
      "source": [
        "#random seed for calibrated equal odds prediction\n",
        "randseed = 12345679 \n",
        "\n",
        "#train validation&test split\n",
        "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.4], shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ZBgebMGStR"
      },
      "source": [
        "# Placeholder for predicted and transformed datasets\n",
        "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
        "\n",
        "# Logistic regression classifier and predictions for training data\n",
        "scale_orig = StandardScaler()\n",
        "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
        "y_train = dataset_orig_train.labels.ravel()\n",
        "lmod = LogisticRegression() #logregression\n",
        "\n",
        "#fit original model\n",
        "lmod.fit(X_train, y_train)\n",
        "\n",
        "fav_idx = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
        "y_train_pred_prob = lmod.predict_proba(X_train)[:,fav_idx]\n",
        "\n",
        "# Prediction probs for training data\n",
        "class_thresh = 0.5\n",
        "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
        "\n",
        "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
        "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
        "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
        "dataset_orig_train_pred.labels = y_train_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWn0aHMmGWDn"
      },
      "source": [
        "#\n",
        "# set up tradeoff cost-benefit calculation\n",
        "include = False\n",
        "N_reps = 1\n",
        "N_values = 50\n",
        "\n",
        "\n",
        "negs = []\n",
        "accs = []\n",
        "fps = []\n",
        "fns = []\n",
        "\n",
        "privileged_options = [True,False,None]\n",
        "\n",
        "\n",
        "#whether to include all fp and all fn cost functions (True)\n",
        "if include == True:\n",
        "    n_range = np.linspace(0.00,1.00,N_values)\n",
        "if include == False:\n",
        "    n_range = np.linspace(0.01,0.99,N_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QQWVhdUGhf3"
      },
      "source": [
        "Set up both variable cep and inquisitiverejectoptionclassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UUky2utGg7D"
      },
      "source": [
        "#set up equalized odds processing\n",
        "cpp = VariableCEP(privileged_groups = privileged_groups,\n",
        "                                        unprivileged_groups = unprivileged_groups,\n",
        "                                        seed=randseed)\n",
        "#ROC\n",
        "ROC = InquisitiveRejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
        "                                 privileged_groups=privileged_groups, \n",
        "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
        "                                  num_class_thresh=100, num_ROC_margin=50,\n",
        "                                  # metric_name=metric_name,\n",
        "                                  metric_ub=0.05, metric_lb=-0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raae9O5MGss8"
      },
      "source": [
        "#for if you're using ROC - which f1, f2 to use for output results AND optimization\n",
        "f1_name = 'false_negative_rate'\n",
        "f2_name = 'false_positive_rate'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVMPpLHIGxI_"
      },
      "source": [
        "#disable to use Mojo's ROC optimiser\n",
        "use_cpp = True\n",
        "\n",
        "#for each fold - validation vs test split\n",
        "split_interv = 0.3\n",
        "\n",
        "#scale size of input range - are these normalized??\n",
        "scale = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HHXicq7G0bv"
      },
      "source": [
        "if use_cpp == True:\n",
        "    post_processor = cpp\n",
        "elif use_cpp == False:\n",
        "    post_processor = ROC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdxrYL2lG2lo"
      },
      "source": [
        "Generate k folds (currently random)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfIFQ7MoG16W"
      },
      "source": [
        "def vt_split_process(dataset_orig_vt,split_indexes,shuf,class_thresh):\n",
        "    dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split(num_or_size_splits=split_indexes,shuffle=shuf,seed=randseed)#validation_test split)\n",
        "    dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
        "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
        "\n",
        "    dataset_new_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
        "    dataset_new_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
        "\n",
        "    X_valid = scale_orig.transform(dataset_orig_valid.features)\n",
        "    y_valid_pred_prob = lmod.predict_proba(X_valid)[:,fav_idx]\n",
        "\n",
        "    X_test = scale_orig.transform(dataset_orig_test.features)\n",
        "    y_test_pred_prob = lmod.predict_proba(X_test)[:,fav_idx]\n",
        "\n",
        "    dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
        "    dataset_orig_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
        "\n",
        "    y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
        "    y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
        "    y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
        "    dataset_orig_valid_pred.labels = y_valid_pred\n",
        "        \n",
        "    y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
        "    y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
        "    y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
        "    dataset_orig_test_pred.labels = y_test_pred\n",
        "\n",
        "    return (dataset_orig_valid, dataset_orig_valid_pred, dataset_orig_test, dataset_orig_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USbzeq6zHHUe"
      },
      "source": [
        "Function to perform cross validation sweep with given weights and function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbagW2EzG4Ym"
      },
      "source": [
        "def determine_cv_values(folds,post_processor,weight_tuple,name_tuple,pbar=None):\n",
        "    for stream in folds:\n",
        "        # Odds equalizing post-processing algorithm\n",
        "\n",
        "        m1,m2,acc = np.zeros(3),np.zeros(3),np.zeros(3)\n",
        "\n",
        "        ##########\n",
        "        dataset_orig_valid, dataset_orig_valid_pred, dataset_orig_test, dataset_orig_test_pred = stream\n",
        "\n",
        "        # Learn parameters to equalize odds and apply to create a new dataset\n",
        "   \n",
        "        if type(post_processor) == VariableCEP:\n",
        "            f1_name = 'false_negative_rate'\n",
        "            f2_name = 'false_positive_rate'\n",
        "            post_processor.set_NP(weight_tuple)\n",
        "            post_processor.fit(dataset_orig_valid, dataset_orig_valid_pred)\n",
        "        elif type(post_processor) == InquisitiveRejectOptionClassification:\n",
        "            f1_name = name_tuple[0]\n",
        "            f2_name = name_tuple[1]\n",
        "\n",
        "            post_processor.fit(dataset_orig_valid, dataset_orig_valid_pred, metric_fn = lambda metric: \n",
        "                            weight_tuple[0]*getattr(metric,f1_name)() + weight_tuple[1]*getattr(metric,f2_name)())\n",
        "\n",
        "        dataset_transf_test_pred = post_processor.predict(dataset_orig_test_pred)\n",
        "\n",
        "        \"\"\"\n",
        "        dataset_transf_valid_pred = post_processor.predict(dataset_orig_valid_pred)\n",
        "        cm_transf_valid = ClassificationMetric(dataset_orig_valid, dataset_transf_valid_pred,\n",
        "                                    unprivileged_groups=unprivileged_groups,\n",
        "                                    privileged_groups=privileged_groups)\n",
        "        \"\"\"\n",
        "        cm_transf_test = ClassificationMetric(dataset_orig_test, dataset_transf_test_pred,\n",
        "                                    unprivileged_groups=unprivileged_groups,\n",
        "                                    privileged_groups=privileged_groups)\n",
        "        #cm_transf_test.difference\n",
        "        \n",
        "        for idx,PR in enumerate(privileged_options):\n",
        "            try:\n",
        "                m1[idx] += getattr(cm_transf_test,f1_name)(privileged=PR)\n",
        "            except Exception:\n",
        "                #for if there is no difference for privileged/unpriveleged groups due to nature of the metric\n",
        "                m1[idx] = 0\n",
        "            try:\n",
        "                m2[idx] += getattr(cm_transf_test,f2_name)(privileged=PR)\n",
        "            except Exception:\n",
        "                m2[idx] = 0\n",
        "            result = cm_transf_test.accuracy(privileged=PR)\n",
        "            acc[idx] += float(result)\n",
        "\n",
        "        out = float(m2[1]/len(folds))\n",
        "        if diag is True:\n",
        "            print(weight_tuple, out)\n",
        "        \n",
        "        if pbar is not None:\n",
        "            pbar.update(1)\n",
        "        else:\n",
        "            return out\n",
        "    return m1/len(folds),m2/len(folds),acc/len(folds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdqEALI0G72r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6966b82d-95d3-42d5-86d4-dde21c3bfb10"
      },
      "source": [
        "#kfold = cross_val_split(n_splits=reruns)\n",
        "\n",
        "folds = []\n",
        "\n",
        "for count in tqdm(range(N_reps)):\n",
        "    si = [split_interv]\n",
        "    folds.append(vt_split_process(dataset_orig_vt=dataset_orig_vt,split_indexes=si,shuf=True,class_thresh=class_thresh))\n",
        "\n",
        "#valid, test = dataset_orig_vt.split(num_or_size_splits=si)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TnpuQouHYLX"
      },
      "source": [
        "Without printing intermediates perform uniform CV search in 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ONOrzOEHQxY"
      },
      "source": [
        "diag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv3GmTcLHXAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bdda405-3680-4042-cbb8-ac4a41e2d8c6"
      },
      "source": [
        "dataset_orig_valid_pred,dataset_orig_test_pred, dataset_new_valid_pred, dataset_new_test_pred = None,None,None,None\n",
        "pbar = tqdm(total=(N_reps*N_values))\n",
        "for neg in n_range:\n",
        "    f1_weight = neg\n",
        "\n",
        "    f2_weight = scale*(1.0 - f1_weight)\n",
        "    f1_weight = scale*f1_weight\n",
        "\n",
        "    w1_score,w2_score,accuracy = determine_cv_values(folds=folds,post_processor=post_processor,weight_tuple=(f1_weight,f2_weight),name_tuple=(f1_name,f2_name),pbar=pbar)\n",
        "\n",
        "    fns.append(w1_score)\n",
        "    fps.append(w2_score)\n",
        "    accs.append(accuracy)\n",
        "    negs.append(neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROGsxek0K11M"
      },
      "source": [
        "Gather max, min values and plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8fgV98aK3yH"
      },
      "source": [
        "# plot results from fns, fps, accs, negs for different groups\n",
        "collapse = lambda param, idx : [v[idx] for v in param]\n",
        "\n",
        "getnames = {None:\"full data\", True:\"privileged\", False:\"unprivileged\"}\n",
        "\n",
        "percentchange = lambda result: [100*((i-result[0])/result[0]) for i in result]\n",
        "\n",
        "idx,PR = 2,None\n",
        "maximised_accuracy = max(collapse(accs,idx))\n",
        "maximised_idx = collapse(accs,idx).index(maximised_accuracy)\n",
        "percentmax = lambda result: [100*((i-result[maximised_idx])/result[maximised_idx]) for i in result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7efRzzuK5nG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27a365d-1c89-4d70-ed2e-841f381ee7a7"
      },
      "source": [
        "maximised_value_idx = lambda prop, idx : collapse(prop,idx).index(max(collapse(prop,idx)))\n",
        "idx = 2\n",
        "values = ['min {}'.format(f1_name),'min {}'.format(f2_name), 'max accuracy']\n",
        "for idv,prop in enumerate([-1*np.array(fps),-1*np.array(fns),accs]):\n",
        "    print(\"\\n\"+values[idv])\n",
        "    maxi = maximised_value_idx(prop,idx)\n",
        "\n",
        "\n",
        "    print(\"{}: {}\".format(f1_name, round(collapse(fps,idx)[maxi],5)))\n",
        "    print(\"{}: {}\".format(f2_name, round(collapse(fns,idx)[maxi],5)))\n",
        "    print(\"accs: {}\".format(round(collapse(accs,idx)[maxi],5)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxS6_UtQK-RH"
      },
      "source": [
        "show accuracy, fp,fn % change from max accuracy for whole model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HyVOv5VK7O5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "0ff98ce0-c32a-4760-9115-e48131430df0"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(negs,percentmax(collapse(accs,idx)),label='accuracy')\n",
        "plt.plot(negs,percentmax(collapse(fns,idx)),label='{}'.format(f1_name))\n",
        "plt.plot(negs,percentmax(collapse(fps,idx)),label='{}'.format(f2_name))\n",
        "plt.xlabel('unnormalized fn rate cost')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('compas1d {}\\nmax_acc={}, fn_cost={}'.format(getnames[PR],round(maximised_accuracy,4),round(negs[maximised_idx],4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbgga8CJLAdX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "683d6329-dbad-450d-d633-c229fbdc9e2d"
      },
      "source": [
        "#show accuracy, fp,fn values % change around the max accuracy for whole model\n",
        "width = 50\n",
        "if maximised_idx < width:\n",
        "    minv,maxv = 0,2*maximised_idx\n",
        "else:\n",
        "    minv,maxv = maximised_idx-width,maximised_idx+width\n",
        "\n",
        "idx,PR = 2,None\n",
        "\n",
        "diceup = lambda lst : lst[minv:maxv]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(diceup(negs),diceup(percentmax(collapse(accs,idx))),label='accuracy')\n",
        "plt.plot(diceup(negs),diceup(percentmax(collapse(fns,idx))),label='{}'.format(f1_name))\n",
        "plt.plot(diceup(negs),diceup(percentmax(collapse(fps,idx))),label='{}'.format(f2_name))\n",
        "plt.xlabel('unnormalized fn rate cost')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('compas1d {}\\nmax_acc={}, fn_cost={}'.format(getnames[PR],round(maximised_accuracy,4),round(negs[maximised_idx],4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O6ZJCcnLDHp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "outputId": "9606bc8f-78c1-4584-a682-8159b61cc878"
      },
      "source": [
        "#show accuracy, fp,fn % change from the start\n",
        "for idx,PR in enumerate(privileged_options):\n",
        "    cost_0 = negs[0]\n",
        "    plt.figure()\n",
        "    plt.plot(negs,percentchange(collapse(accs,idx)),label='accuracy')\n",
        "    plt.plot(negs,percentchange(collapse(fns,idx)),label='{}'.format(f1_name))\n",
        "    plt.plot(negs,percentchange(collapse(fps,idx)),label='{}'.format(f2_name))\n",
        "    plt.xlabel('unnormalized fn rate cost')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title('compas1d {}\\npercent change over fn_cost={}'.format(getnames[PR],cost_0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X40YaKAKLExV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82df3078-bc23-4ceb-e39f-6cf30c7a2bfe"
      },
      "source": [
        "#show raw accuracy,fp,fn\n",
        "for idx,PR in enumerate(privileged_options):\n",
        "    plt.figure()\n",
        "    plt.plot(negs,collapse(accs,idx),label='accuracy')\n",
        "    plt.plot(negs,collapse(fns,idx),label='{}'.format(f1_name))\n",
        "    plt.plot(negs,collapse(fps,idx),label='{}'.format(f2_name))\n",
        "    plt.xlabel('unnormalized fn rate cost')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title('compas1d {}'.format(getnames[PR]))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(negs,collapse(accs,idx),label='accuracy')\n",
        "    plt.xlabel('unnormalized fn rate cost')\n",
        "    plt.legend()\n",
        "    plt.title('compas1d_acc {}'.format(getnames[PR]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3aTI1fILHXA"
      },
      "source": [
        "Search using BasinHopping Optimizer (currently broken)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhgjsp7yLKXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcba35b8-546f-40f8-d0a7-4544adbe6e1a"
      },
      "source": [
        "#OPTIMIZE SEARCH\n",
        "diag = True\n",
        "process = lambda weight : [weight, 1-weight]\n",
        "to_opt = lambda weights : -1*determine_cv_values(folds=folds,post_processor=post_processor,weight_tuple=process(weights[0]),name_tuple=(f1_name,f2_name))\n",
        "res = optimize.basinhopping(func=to_opt,x0 = np.array([0.3]))\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}