{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "demo_reject_option_classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SammyDMartin/fairness/blob/main/parameter_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXgPpTHixLGo"
      },
      "source": [
        "# Contribution\n",
        "**Add the possibility to pass in arbitrary metric to the ROC or CPP fit function**\n",
        "\n",
        "**Perform (currently random) cross-validation search over weights in arbitarary fairness function and assess k-fold accuracy/fairness scores**\n",
        "\n",
        "*search over fairness weight hyperparameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDPhtiySyDZW"
      },
      "source": [
        "### **Step 1**\n",
        "Install aif360 and setup environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU-3Yn931e7G",
        "outputId": "0f08c863-e97f-43e6-c3d8-8c0f4a9c8b65"
      },
      "source": [
        "!git clone https://github.com/Trusted-AI/AIF360"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'AIF360' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrLI8Amk1m5l",
        "outputId": "c499b150-676d-4f83-8b9a-49678e0ad4d2"
      },
      "source": [
        "%cd AIF360 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/AIF360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rRhJVUXMs6U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2f86f4-031d-4562-ee83-669ef4e5f0e2"
      },
      "source": [
        "%pip install '.[all]'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/AIF360\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: scipy<1.6.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (1.1.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (3.2.2)\n",
            "Requirement already satisfied: tempeh in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (0.1.12)\n",
            "Requirement already satisfied: BlackBoxAuditing in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (0.1.54)\n",
            "Requirement already satisfied: adversarial-robustness-toolbox>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (1.6.0)\n",
            "Requirement already satisfied: tensorflow>=1.13.1 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: fairlearn==0.4.6 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (0.4.6)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (0.2.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (4.41.1)\n",
            "Requirement already satisfied: sphinx_rtd_theme in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (0.5.2)\n",
            "Requirement already satisfied: pytest>=3.5 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (3.6.4)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (1.0.31)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (1.0.0)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.7/dist-packages (from aif360==0.4.0) (1.8.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360==0.4.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->aif360==0.4.0) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->aif360==0.4.0) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.4.0) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.4.0) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->aif360==0.4.0) (2.4.7)\n",
            "Requirement already satisfied: memory-profiler in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360==0.4.0) (0.58.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360==0.4.0) (2.23.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.7/dist-packages (from tempeh->aif360==0.4.0) (0.39.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from BlackBoxAuditing->aif360==0.4.0) (2.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.10.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.25.1)\n",
            "Requirement already satisfied: mypy in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.812)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: cma in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (3.0.3)\n",
            "Requirement already satisfied: numba~=0.52.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.52.0)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (54.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (0.12.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (2.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (0.36.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (1.1.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (0.3.3)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.13.1->aif360==0.4.0) (3.12.4)\n",
            "Requirement already satisfied: ipywidgets>=7.5.0 in /usr/local/lib/python3.7/dist-packages (from fairlearn==0.4.6->aif360==0.4.0) (7.6.3)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime->aif360==0.4.0) (0.16.2)\n",
            "Requirement already satisfied: docutils<0.17 in /usr/local/lib/python3.7/dist-packages (from sphinx_rtd_theme->aif360==0.4.0) (0.16)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.5->aif360==0.4.0) (8.7.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.5->aif360==0.4.0) (20.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.5->aif360==0.4.0) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.5->aif360==0.4.0) (1.10.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest>=3.5->aif360==0.4.0) (1.4.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->aif360==0.4.0) (0.6.2.post0)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->aif360==0.4.0) (2.1.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->aif360==0.4.0) (0.70.11.1)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.7/dist-packages (from cvxpy>=1.0->aif360==0.4.0) (2.0.7.post1)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->aif360==0.4.0) (4.10.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->aif360==0.4.0) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->aif360==0.4.0) (5.3.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->aif360==0.4.0) (5.0.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->aif360==0.4.0) (5.6.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.7/dist-packages (from sphinx->aif360==0.4.0) (0.7.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from sphinx->aif360==0.4.0) (20.9)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.7/dist-packages (from sphinx->aif360==0.4.0) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.7/dist-packages (from sphinx->aif360==0.4.0) (1.2.4)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->aif360==0.4.0) (2.11.3)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.7/dist-packages (from sphinx->aif360==0.4.0) (2.9.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.7/dist-packages (from sphinx->aif360==0.4.0) (1.2.0)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.7/dist-packages (from sphinx->aif360==0.4.0) (2.6.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from memory-profiler->tempeh->aif360==0.4.0) (5.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360==0.4.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360==0.4.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360==0.4.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tempeh->aif360==0.4.0) (3.0.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: slicer==0.0.7 in /usr/local/lib/python3.7/dist-packages (from shap->tempeh->aif360==0.4.0) (0.0.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->BlackBoxAuditing->aif360==0.4.0) (4.4.2)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.5.1)\n",
            "Requirement already satisfied: mypy-extensions<0.5.0,>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from mypy->adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.4.3)\n",
            "Requirement already satisfied: typed-ast<1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from mypy->adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (1.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python->adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.16.0)\n",
            "Requirement already satisfied: llvmlite<0.36,>=0.35.0 in /usr/local/lib/python3.7/dist-packages (from numba~=0.52.0->adversarial-robustness-toolbox>=1.0.0->aif360==0.4.0) (0.35.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (1.28.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (0.4.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (1.0.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (5.1.2)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (5.0.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime->aif360==0.4.0) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime->aif360==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.7/dist-packages (from osqp>=0.4.1->cvxpy>=1.0->aif360==0.4.0) (0.1.5.post0)\n",
            "Requirement already satisfied: dill>=0.3.3 in /usr/local/lib/python3.7/dist-packages (from multiprocess->cvxpy>=1.0->aif360==0.4.0) (0.3.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->aif360==0.4.0) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->aif360==0.4.0) (5.3.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->aif360==0.4.0) (1.0.18)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->aif360==0.4.0) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->aif360==0.4.0) (0.9.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->aif360==0.4.0) (4.7.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->aif360==0.4.0) (1.5.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->aif360==0.4.0) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->aif360==0.4.0) (22.0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->aif360==0.4.0) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->aif360==0.4.0) (0.4.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->aif360==0.4.0) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->aif360==0.4.0) (3.3.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->aif360==0.4.0) (1.4.3)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->aif360==0.4.0) (0.3)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.7/dist-packages (from sphinxcontrib-websupport->sphinx->aif360==0.4.0) (1.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.3->sphinx->aif360==0.4.0) (1.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (3.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (2.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.5.0->fairlearn==0.4.6->aif360==0.4.0) (4.8.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->aif360==0.4.0) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->aif360==0.4.0) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->aif360==0.4.0) (0.5.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.13.1->aif360==0.4.0) (3.4.1)\n",
            "Building wheels for collected packages: aif360\n",
            "  Building wheel for aif360 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aif360: filename=aif360-0.4.0-cp37-none-any.whl size=557693 sha256=a46a97df28b3097847ec06478691cb1216f605f42e0df72191ae5ba94dddbf0d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-b19fvihj/wheels/98/c1/ab/d8fba482498b80dd95f0c1940d349fb383ee734c04245e4a8e\n",
            "Successfully built aif360\n",
            "Installing collected packages: aif360\n",
            "  Found existing installation: aif360 0.4.0\n",
            "    Uninstalling aif360-0.4.0:\n",
            "      Successfully uninstalled aif360-0.4.0\n",
            "Successfully installed aif360-0.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31V3grha3NNR"
      },
      "source": [
        "Download data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk-DyqaK3PxM",
        "outputId": "f11c9a88-84e2-47b6-8de5-37a4e17b52a3"
      },
      "source": [
        "import urllib.request \n",
        "\n",
        "urls = [\n",
        "  \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",\n",
        "\t\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\",\n",
        "\t\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\",\n",
        "]\n",
        "\n",
        "filenames = [\n",
        "  \"/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.data\",\n",
        "  \"/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.test\",\n",
        "  \"/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.names\",\n",
        "]\n",
        "\n",
        "for i in range(len(urls)):\n",
        "  url = urls[i]\n",
        "  filename = filenames[i]\n",
        "  print(url)\n",
        "  print(filename)\n",
        "  urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
            "/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.data\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\n",
            "/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.test\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\n",
            "/usr/local/lib/python3.7/dist-packages/aif360/data/raw/adult/adult.names\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaFfNOHqUfvA",
        "outputId": "e1f7b4d1-5f37-4ce3-dad3-a1bef266b060"
      },
      "source": [
        "%cd examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/AIF360/examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0XaaJklFFTP"
      },
      "source": [
        "Define Modified CalibratedEqOddsPostprocessing and Reject Option Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVPYyLHAECFh"
      },
      "source": [
        "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
        "from aif360.metrics.binary_label_dataset_metric import BinaryLabelDatasetMetric\n",
        "from aif360.metrics.classification_metric import ClassificationMetric\n",
        "import numpy as np\n",
        "\n",
        "class VariableCEP(CalibratedEqOddsPostprocessing):\n",
        "    def set_NP(self, NP_rate):\n",
        "        self.fn_rate = NP_rate[0]\n",
        "        self.fp_rate = NP_rate[1]\n",
        "    \n",
        "\n",
        "def normed_rates(fp_rate, fn_rate):\n",
        "    norm_const = float(fp_rate + fn_rate) if\\\n",
        "                      (fp_rate != 0 and fn_rate != 0) else 1\n",
        "    return (fp_rate / norm_const), (fn_rate / norm_const)\n",
        "\n",
        "\n",
        "from aif360.algorithms.postprocessing.reject_option_classification\\\n",
        "        import RejectOptionClassification\n",
        "\n",
        "class InquisitiveRejectOptionClassification(RejectOptionClassification):\n",
        "\n",
        "  def fit(self, dataset_true, dataset_pred, metric_fn=None):\n",
        "      \"\"\"Estimates the optimal classification threshold and margin for reject\n",
        "      option classification that optimizes the metric provided.\n",
        "      Note:\n",
        "          The `fit` function is a no-op for this algorithm.\n",
        "      Args:\n",
        "          dataset_true (BinaryLabelDataset): Dataset containing the true\n",
        "              `labels`.\n",
        "          dataset_pred (BinaryLabelDataset): Dataset containing the predicted\n",
        "              `scores`.\n",
        "      Returns:\n",
        "          RejectOptionClassification: Returns self.\n",
        "      \"\"\"\n",
        "      fair_metric_arr = np.zeros(self.num_class_thresh*self.num_ROC_margin)\n",
        "      balanced_acc_arr = np.zeros_like(fair_metric_arr)\n",
        "      ROC_margin_arr = np.zeros_like(fair_metric_arr)\n",
        "      class_thresh_arr = np.zeros_like(fair_metric_arr)\n",
        "\n",
        "      cnt = 0\n",
        "      # Iterate through class thresholds\n",
        "      for class_thresh in np.linspace(self.low_class_thresh,\n",
        "                                      self.high_class_thresh,\n",
        "                                      self.num_class_thresh):\n",
        "\n",
        "          self.classification_threshold = class_thresh\n",
        "          if class_thresh <= 0.5:\n",
        "              low_ROC_margin = 0.0\n",
        "              high_ROC_margin = class_thresh\n",
        "          else:\n",
        "              low_ROC_margin = 0.0\n",
        "              high_ROC_margin = (1.0-class_thresh)\n",
        "\n",
        "          # Iterate through ROC margins\n",
        "          for ROC_margin in np.linspace(\n",
        "                              low_ROC_margin,\n",
        "                              high_ROC_margin,\n",
        "                              self.num_ROC_margin):\n",
        "              self.ROC_margin = ROC_margin\n",
        "\n",
        "              # Predict using the current threshold and margin\n",
        "              dataset_transf_pred = self.predict(dataset_pred)\n",
        "\n",
        "              dataset_transf_metric_pred = BinaryLabelDatasetMetric(\n",
        "                                            dataset_transf_pred,\n",
        "                                            unprivileged_groups=self.unprivileged_groups,\n",
        "                                            privileged_groups=self.privileged_groups)\n",
        "              classified_transf_metric = ClassificationMetric(\n",
        "                                            dataset_true,\n",
        "                                            dataset_transf_pred,\n",
        "                                            unprivileged_groups=self.unprivileged_groups,\n",
        "                                            privileged_groups=self.privileged_groups)\n",
        "\n",
        "              ROC_margin_arr[cnt] = self.ROC_margin\n",
        "              class_thresh_arr[cnt] = self.classification_threshold\n",
        "\n",
        "              # Balanced accuracy and fairness metric computations\n",
        "              balanced_acc_arr[cnt] = 0.5*(classified_transf_metric.true_positive_rate()\\\n",
        "                                      +classified_transf_metric.true_negative_rate())\n",
        "              \n",
        "              ### THE ONLY CHANGE I MAKE TO THE FUNCTION IS HERE\n",
        "              if metric_fn:\n",
        "                  fair_metric_arr[cnt] = metric_fn(classified_transf_metric)\n",
        "              ###\n",
        "              \n",
        "              elif self.metric_name == \"Statistical parity difference\":\n",
        "                  fair_metric_arr[cnt] = dataset_transf_metric_pred.mean_difference()\n",
        "              elif self.metric_name == \"Average odds difference\":\n",
        "                  fair_metric_arr[cnt] = classified_transf_metric.average_odds_difference()\n",
        "              elif self.metric_name == \"Equal opportunity difference\":\n",
        "                  fair_metric_arr[cnt] = classified_transf_metric.equal_opportunity_difference()\n",
        "              \n",
        "              \n",
        "\n",
        "              cnt += 1\n",
        "\n",
        "      rel_inds = np.logical_and(fair_metric_arr >= self.metric_lb,\n",
        "                                fair_metric_arr <= self.metric_ub)\n",
        "      if any(rel_inds):\n",
        "          best_ind = np.where(balanced_acc_arr[rel_inds]\n",
        "                              == np.max(balanced_acc_arr[rel_inds]))[0][0]\n",
        "      else:\n",
        "          print(\"Unable to satisfy fairness constraints\")\n",
        "          rel_inds = np.ones(len(fair_metric_arr), dtype=bool)\n",
        "          best_ind = np.where(fair_metric_arr[rel_inds]\n",
        "                              == np.min(fair_metric_arr[rel_inds]))[0][0]\n",
        "\n",
        "      self.ROC_margin = ROC_margin_arr[rel_inds][best_ind]\n",
        "      self.classification_threshold = class_thresh_arr[rel_inds][best_ind]\n",
        "\n",
        "      return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W45OSKC6FMby"
      },
      "source": [
        "Import Everything needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4MRumjXE_Br"
      },
      "source": [
        "# Load all necessary packages\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.append(\"../\")\n",
        "from aif360.datasets import AdultDataset, GermanDataset, CompasDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.metrics import ClassificationMetric\n",
        "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions\\\n",
        "                import load_preproc_data_adult, load_preproc_data_compas\n",
        "\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "from sklearn.model_selection import KFold as cross_val_split\n",
        "from scipy import optimize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkS9_FuTEmV7"
      },
      "source": [
        "## import dataset - use compas\n",
        "dataset_used = \"adult\" # \"adult\", \"german\", \"compas\"\n",
        "protected_attribute_used = 2 # 1, 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhNVAv3fEq93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b5eb96-5753-456b-9272-66bb7ce97e83"
      },
      "source": [
        "# code to identify the protected attributes from all of the dataset features\n",
        "if dataset_used == \"adult\":\n",
        "    dataset_orig = AdultDataset()\n",
        "#     dataset_orig = load_preproc_data_adult()\n",
        "    if protected_attribute_used == 1:\n",
        "        privileged_groups = [{'sex': 1}]\n",
        "        unprivileged_groups = [{'sex': 0}]\n",
        "    else:\n",
        "        privileged_groups = [{'race': 1}]\n",
        "        unprivileged_groups = [{'race': 0}]\n",
        "    \n",
        "elif dataset_used == \"german\":\n",
        "    dataset_orig = GermanDataset()\n",
        "    if protected_attribute_used == 1:\n",
        "        privileged_groups = [{'sex': 1}]\n",
        "        unprivileged_groups = [{'sex': 0}]\n",
        "    else:\n",
        "        privileged_groups = [{'age': 1}]\n",
        "        unprivileged_groups = [{'age': 0}]\n",
        "    \n",
        "elif dataset_used == \"compas\":\n",
        "#     dataset_orig = CompasDataset()\n",
        "    dataset_orig = load_preproc_data_compas()\n",
        "    if protected_attribute_used == 1:\n",
        "        privileged_groups = [{'sex': 1}]\n",
        "        unprivileged_groups = [{'sex': 0}]\n",
        "    else:\n",
        "        privileged_groups = [{'race': 1}]\n",
        "        unprivileged_groups = [{'race': 0}]  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Missing Data: 3620 rows removed from AdultDataset.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKwIcBsRGPEQ"
      },
      "source": [
        "#random seed for calibrated equal odds prediction\n",
        "randseed = 12345679 \n",
        "\n",
        "#train validation&test split\n",
        "dataset_orig_train, dataset_orig_vt = dataset_orig.split([0.6], shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80ZBgebMGStR"
      },
      "source": [
        "# Placeholder for predicted and transformed datasets\n",
        "dataset_orig_train_pred = dataset_orig_train.copy(deepcopy=True)\n",
        "\n",
        "# Logistic regression classifier and predictions for training data\n",
        "scale_orig = StandardScaler()\n",
        "X_train = scale_orig.fit_transform(dataset_orig_train.features)\n",
        "y_train = dataset_orig_train.labels.ravel()\n",
        "lmod = LogisticRegression() #logregression\n",
        "\n",
        "#fit original model\n",
        "lmod.fit(X_train, y_train)\n",
        "\n",
        "fav_idx = np.where(lmod.classes_ == dataset_orig_train.favorable_label)[0][0]\n",
        "y_train_pred_prob = lmod.predict_proba(X_train)[:,fav_idx]\n",
        "\n",
        "# Prediction probs for training data\n",
        "class_thresh = 0.5\n",
        "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
        "\n",
        "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
        "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
        "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
        "dataset_orig_train_pred.labels = y_train_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWn0aHMmGWDn"
      },
      "source": [
        "#\n",
        "# set up tradeoff cost-benefit calculation\n",
        "include = False\n",
        "N_reps = 10\n",
        "N_values = 50\n",
        "\n",
        "\n",
        "negs = []\n",
        "accs = []\n",
        "fps = []\n",
        "fns = []\n",
        "\n",
        "privileged_options = [True,False,None]\n",
        "\n",
        "\n",
        "#whether to include all fp and all fn cost functions (True)\n",
        "if include == True:\n",
        "    n_range = np.linspace(0.00,1.00,N_values)\n",
        "if include == False:\n",
        "    n_range = np.linspace(0.01,0.99,N_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QQWVhdUGhf3"
      },
      "source": [
        "Set up both variable cep and inquisitiverejectoptionclassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UUky2utGg7D"
      },
      "source": [
        "#set up equalized odds processing\n",
        "cpp = VariableCEP(privileged_groups = privileged_groups,\n",
        "                                        unprivileged_groups = unprivileged_groups,\n",
        "                                        seed=randseed)\n",
        "#ROC\n",
        "ROC = InquisitiveRejectOptionClassification(unprivileged_groups=unprivileged_groups, \n",
        "                                 privileged_groups=privileged_groups, \n",
        "                                 low_class_thresh=0.01, high_class_thresh=0.99,\n",
        "                                  num_class_thresh=100, num_ROC_margin=50,\n",
        "                                  # metric_name=metric_name,\n",
        "                                  metric_ub=0.05, metric_lb=-0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Raae9O5MGss8"
      },
      "source": [
        "#for if you're using ROC - which f1, f2 to use for output results AND optimization\n",
        "f1_name = 'false_negative_rate'\n",
        "f2_name = 'false_positive_rate'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVMPpLHIGxI_"
      },
      "source": [
        "#disable to use Mojo's ROC optimiser\n",
        "use_cpp = True\n",
        "split_interv = 0.2\n",
        "\n",
        "#scale size of input range - are these normalized??\n",
        "scale = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HHXicq7G0bv"
      },
      "source": [
        "if use_cpp == True:\n",
        "    post_processor = cpp\n",
        "elif use_cpp == False:\n",
        "    post_processor = ROC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdxrYL2lG2lo"
      },
      "source": [
        "Generate k folds (currently random)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfIFQ7MoG16W"
      },
      "source": [
        "def vt_split_process(dataset_orig_vt,split_indexes,shuf,class_thresh):\n",
        "    dataset_orig_valid, dataset_orig_test = dataset_orig_vt.split(num_or_size_splits=split_indexes,shuffle=shuf,seed=randseed)#validation_test split)\n",
        "    dataset_orig_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
        "    dataset_orig_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
        "\n",
        "    dataset_new_valid_pred = dataset_orig_valid.copy(deepcopy=True)\n",
        "    dataset_new_test_pred = dataset_orig_test.copy(deepcopy=True)\n",
        "\n",
        "    X_valid = scale_orig.transform(dataset_orig_valid.features)\n",
        "    y_valid_pred_prob = lmod.predict_proba(X_valid)[:,fav_idx]\n",
        "\n",
        "    X_test = scale_orig.transform(dataset_orig_test.features)\n",
        "    y_test_pred_prob = lmod.predict_proba(X_test)[:,fav_idx]\n",
        "\n",
        "    dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
        "    dataset_orig_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
        "\n",
        "    y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
        "    y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
        "    y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
        "    dataset_orig_valid_pred.labels = y_valid_pred\n",
        "        \n",
        "    y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
        "    y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
        "    y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
        "    dataset_orig_test_pred.labels = y_test_pred\n",
        "\n",
        "    return (dataset_orig_valid, dataset_orig_valid_pred, dataset_orig_test, dataset_orig_test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USbzeq6zHHUe"
      },
      "source": [
        "Function to perform cross validation sweep with given weights and function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbagW2EzG4Ym"
      },
      "source": [
        "def determine_cv_values(folds,post_processor,weight_tuple,name_tuple,pbar=None):\n",
        "    for stream in folds:\n",
        "        # Odds equalizing post-processing algorithm\n",
        "\n",
        "        m1,m2,acc = np.zeros(3),np.zeros(3),np.zeros(3)\n",
        "\n",
        "        ##########\n",
        "        dataset_orig_valid, dataset_orig_valid_pred, dataset_orig_test, dataset_orig_test_pred = stream\n",
        "\n",
        "        # Learn parameters to equalize odds and apply to create a new dataset\n",
        "   \n",
        "        if type(post_processor) == VariableCEP:\n",
        "            f1_name = 'false_negative_rate'\n",
        "            f2_name = 'false_positive_rate'\n",
        "            post_processor.set_NP(weight_tuple)\n",
        "            post_processor.fit(dataset_orig_valid, dataset_orig_valid_pred)\n",
        "        elif type(post_processor) == InquisitiveRejectOptionClassification:\n",
        "            f1_name = name_tuple[0]\n",
        "            f2_name = name_tuple[1]\n",
        "\n",
        "            post_processor.fit(dataset_orig_valid, dataset_orig_valid_pred, metric_fn = lambda metric: \n",
        "                            weight_tuple[0]*getattr(metric,f1_name)() + weight_tuple[1]*getattr(metric,f2_name)())\n",
        "\n",
        "        dataset_transf_test_pred = post_processor.predict(dataset_orig_test_pred)\n",
        "\n",
        "        \"\"\"\n",
        "        dataset_transf_valid_pred = post_processor.predict(dataset_orig_valid_pred)\n",
        "        cm_transf_valid = ClassificationMetric(dataset_orig_valid, dataset_transf_valid_pred,\n",
        "                                    unprivileged_groups=unprivileged_groups,\n",
        "                                    privileged_groups=privileged_groups)\n",
        "        \"\"\"\n",
        "        cm_transf_test = ClassificationMetric(dataset_orig_test, dataset_transf_test_pred,\n",
        "                                    unprivileged_groups=unprivileged_groups,\n",
        "                                    privileged_groups=privileged_groups)\n",
        "        #cm_transf_test.difference\n",
        "        \n",
        "        for idx,PR in enumerate(privileged_options):\n",
        "            try:\n",
        "                m1[idx] += getattr(cm_transf_test,f1_name)(privileged=PR)\n",
        "            except Exception:\n",
        "                #for if there is no difference for privileged/unpriveleged groups due to nature of the metric\n",
        "                m1[idx] = 0\n",
        "            try:\n",
        "                m2[idx] += getattr(cm_transf_test,f2_name)(privileged=PR)\n",
        "            except Exception:\n",
        "                m2[idx] = 0\n",
        "            result = cm_transf_test.accuracy(privileged=PR)\n",
        "            acc[idx] += float(result)\n",
        "\n",
        "        out = float(m2[1]/len(folds))\n",
        "        if diag is True:\n",
        "            print(weight_tuple, out)\n",
        "        \n",
        "        if pbar is not None:\n",
        "            pbar.update(1)\n",
        "        else:\n",
        "            return out\n",
        "    return m1/len(folds),m2/len(folds),acc/len(folds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdqEALI0G72r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6a3bea-c3b9-4e6d-eee8-9725866bccf9"
      },
      "source": [
        "#kfold = cross_val_split(n_splits=reruns)\n",
        "\n",
        "folds = []\n",
        "\n",
        "for count in tqdm(range(N_reps)):\n",
        "    si = [split_interv]\n",
        "    folds.append(vt_split_process(dataset_orig_vt=dataset_orig_vt,split_indexes=si,shuf=True,class_thresh=class_thresh))\n",
        "\n",
        "#valid, test = dataset_orig_vt.split(num_or_size_splits=si)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|| 10/10 [00:03<00:00,  2.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TnpuQouHYLX"
      },
      "source": [
        "Without printing intermediates perform uniform CV search in 1D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ONOrzOEHQxY"
      },
      "source": [
        "diag = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv3GmTcLHXAH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f60f117-4648-4178-eaab-784469763169"
      },
      "source": [
        "dataset_orig_valid_pred,dataset_orig_test_pred, dataset_new_valid_pred, dataset_new_test_pred = None,None,None,None\n",
        "pbar = tqdm(total=(N_reps*N_values))\n",
        "for neg in n_range:\n",
        "    f1_weight = neg\n",
        "\n",
        "    f2_weight = scale*(1.0 - f1_weight)\n",
        "    f1_weight = scale*f1_weight\n",
        "\n",
        "    w1_score,w2_score,accuracy = determine_cv_values(folds=folds,post_processor=post_processor,weight_tuple=(f1_weight,f2_weight),name_tuple=(f1_name,f2_name),pbar=pbar)\n",
        "\n",
        "    fns.append(w1_score)\n",
        "    fps.append(w2_score)\n",
        "    accs.append(accuracy)\n",
        "    negs.append(neg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  9%|         | 47/500 [00:12<02:03,  3.66it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROGsxek0K11M"
      },
      "source": [
        "Gather max, min values and plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8fgV98aK3yH"
      },
      "source": [
        "# plot results from fns, fps, accs, negs for different groups\n",
        "collapse = lambda param, idx : [v[idx] for v in param]\n",
        "\n",
        "getnames = {None:\"full data\", True:\"privileged\", False:\"unprivileged\"}\n",
        "\n",
        "percentchange = lambda result: [100*((i-result[0])/result[0]) for i in result]\n",
        "\n",
        "idx,PR = 2,None\n",
        "maximised_accuracy = max(collapse(accs,idx))\n",
        "maximised_idx = collapse(accs,idx).index(maximised_accuracy)\n",
        "percentmax = lambda result: [100*((i-result[maximised_idx])/result[maximised_idx]) for i in result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7efRzzuK5nG"
      },
      "source": [
        "maximised_value_idx = lambda prop, idx : collapse(prop,idx).index(max(collapse(prop,idx)))\n",
        "idx = 2\n",
        "values = ['min {}'.format(f1_name),'min {}'.format(f2_name), 'max accuracy']\n",
        "for idv,prop in enumerate([-1*np.array(fps),-1*np.array(fns),accs]):\n",
        "    print(\"\\n\"+values[idv])\n",
        "    maxi = maximised_value_idx(prop,idx)\n",
        "\n",
        "\n",
        "    print(\"{}: {}\".format(f1_name, round(collapse(fps,idx)[maxi],5)))\n",
        "    print(\"{}: {}\".format(f2_name, round(collapse(fns,idx)[maxi],5)))\n",
        "    print(\"accs: {}\".format(round(collapse(accs,idx)[maxi],5)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxS6_UtQK-RH"
      },
      "source": [
        "show accuracy, fp,fn % change from max accuracy for whole model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HyVOv5VK7O5"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(negs,percentmax(collapse(accs,idx)),label='accuracy')\n",
        "plt.plot(negs,percentmax(collapse(fns,idx)),label='{}'.format(f1_name))\n",
        "plt.plot(negs,percentmax(collapse(fps,idx)),label='{}'.format(f2_name))\n",
        "plt.xlabel('unnormalized fn rate cost')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('compas1d {}\\nmax_acc={}, fn_cost={}'.format(getnames[PR],round(maximised_accuracy,4),round(negs[maximised_idx],4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbgga8CJLAdX"
      },
      "source": [
        "#show accuracy, fp,fn values % change around the max accuracy for whole model\n",
        "width = 50\n",
        "if maximised_idx < width:\n",
        "    minv,maxv = 0,2*maximised_idx\n",
        "else:\n",
        "    minv,maxv = maximised_idx-width,maximised_idx+width\n",
        "\n",
        "idx,PR = 2,None\n",
        "\n",
        "diceup = lambda lst : lst[minv:maxv]\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(diceup(negs),diceup(percentmax(collapse(accs,idx))),label='accuracy')\n",
        "plt.plot(diceup(negs),diceup(percentmax(collapse(fns,idx))),label='{}'.format(f1_name))\n",
        "plt.plot(diceup(negs),diceup(percentmax(collapse(fps,idx))),label='{}'.format(f2_name))\n",
        "plt.xlabel('unnormalized fn rate cost')\n",
        "\n",
        "plt.legend()\n",
        "plt.title('compas1d {}\\nmax_acc={}, fn_cost={}'.format(getnames[PR],round(maximised_accuracy,4),round(negs[maximised_idx],4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O6ZJCcnLDHp"
      },
      "source": [
        "#show accuracy, fp,fn % change from the start\n",
        "for idx,PR in enumerate(privileged_options):\n",
        "    cost_0 = negs[0]\n",
        "    plt.figure()\n",
        "    plt.plot(negs,percentchange(collapse(accs,idx)),label='accuracy')\n",
        "    plt.plot(negs,percentchange(collapse(fns,idx)),label='{}'.format(f1_name))\n",
        "    plt.plot(negs,percentchange(collapse(fps,idx)),label='{}'.format(f2_name))\n",
        "    plt.xlabel('unnormalized fn rate cost')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title('compas1d {}\\npercent change over fn_cost={}'.format(getnames[PR],cost_0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X40YaKAKLExV"
      },
      "source": [
        "#show raw accuracy,fp,fn\n",
        "for idx,PR in enumerate(privileged_options):\n",
        "    plt.figure()\n",
        "    plt.plot(negs,collapse(accs,idx),label='accuracy')\n",
        "    plt.plot(negs,collapse(fns,idx),label='{}'.format(f1_name))\n",
        "    plt.plot(negs,collapse(fps,idx),label='{}'.format(f2_name))\n",
        "    plt.xlabel('unnormalized fn rate cost')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title('compas1d {}'.format(getnames[PR]))\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(negs,collapse(accs,idx),label='accuracy')\n",
        "    plt.xlabel('unnormalized fn rate cost')\n",
        "    plt.legend()\n",
        "    plt.title('compas1d_acc {}'.format(getnames[PR]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3aTI1fILHXA"
      },
      "source": [
        "Search using BasinHopping Optimizer (currently broken)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhgjsp7yLKXI"
      },
      "source": [
        "#OPTIMIZE SEARCH\n",
        "diag = True\n",
        "process = lambda weight : [weight, 1-weight]\n",
        "to_opt = lambda weights : -1*determine_cv_values(folds=folds,post_processor=post_processor,weight_tuple=process(weights[0]),name_tuple=(f1_name,f2_name))\n",
        "res = optimize.basinhopping(func=to_opt,x0 = np.array([0.3]))\n",
        "print(res)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}